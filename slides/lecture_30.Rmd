---
author: "Dr. Ciaran Evans"
title: Introduction to logistic regression
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

## Agenda

* Project 2 released, due November 15
* Lab 6: Johe has left some detailed comments
* STA courses
* Quick discussion of quiz 4
* Today: beginning logistic regression

---

## STA courses next semester

Intermediate courses (200-level)

* STA 279 Categorical and multilevel models
    * Follows 112, more about model building and different types of regression
    * Relaxing some assumptions from 112
* STA 247 Design and sampling
    * data collection, observational studies, experiments
    
---

## Quiz 4

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
library(tidyverse)
library(Stat2Data)
data("MedGPA")

set.seed(3)

x = rnorm(100, mean=50, sd=15)
sim_data <- data.frame(Noise = rep(c("ocean", "ship"), each = 50),
                       Mass = x,
                       Oxygen = c(50 + 2*x[1:50] + rnorm(50, sd=15),
                                  300 - 2*x[51:100] + rnorm(50, sd=15)))

sim_data %>%
  ggplot(aes(x = Mass, y = Oxygen, color = Noise)) +
  geom_point(size=2) +
  theme_bw() +
  theme(text = element_text(size=20))
```

* **Question 1:** Based on the scatterplot, model 3 is most appropriate because an interaction is needed to capture the different slopes for different noise types
* **Question 3:** The researchers want to test whether the slope is different for different noise types. $H_0: \beta_3 = 0$ vs. $H_A: \beta_3 \neq 0$, where $\beta_3$ is the coefficient for the interaction between mass and noise
    
---

## Quiz 4

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
library(tidyverse)
library(Stat2Data)
data("MedGPA")

set.seed(3)

x = rnorm(100, mean=50, sd=15)
sim_data <- data.frame(Noise = rep(c("ocean", "ship"), each = 50),
                       Mass = x,
                       Oxygen = c(50 + 2*x[1:50] + rnorm(50, sd=15),
                                  300 - 2*x[51:100] + rnorm(50, sd=15)))

sim_data %>%
  ggplot(aes(x = Mass, y = Oxygen, color = Noise)) +
  geom_point(size=2) +
  theme_bw() +
  theme(text = element_text(size=20))
```

* **Question 3:** The researchers want to test whether the slope is different for different noise types. $H_0: \beta_3 = 0$ vs. $H_A: \beta_3 \neq 0$, where $\beta_3$ is the coefficient for the interaction between mass and noise
* **Question 4:** 
    * reduced model: $\text{oxygen} = \beta_0 + \beta_1 \text{IsShip} + \beta_2 \text{Mass} + \varepsilon$
    * full model: $\text{oxygen} = \beta_0 + \beta_1 \text{IsShip} + \beta_2 \text{Mass} + \beta_3 \text{IsShip} \cdot \text{Mass} + \varepsilon$

---

## Linear regression

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
MedGPA %>%
  ggplot(aes(x = GPA, y = MCAT)) +
  geom_point() +
  geom_smooth(se=F, method="lm") +
  labs(x = "College GPA",
       y = "MCAT score") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

$\text{MCAT} = \beta_0 + \beta_1 \text{GPA} + \varepsilon$

* $\beta_0 + \beta_1 \text{GPA} =$ average MCAT score for given GPA

.question[
MCAT score is a quantitative response. What if our response isn't quantitative?
]

---

## Binary response

$\text{Accepted} = 1$ if accepted, $0$ otherwise

**Initial idea:** $P(\text{Accepted} = 1) = \beta_0 + \beta_1 \text{GPA}$ = "average" acceptance given GPA

* $P(\text{Accepted} = 1) =$ probability of acceptance

--

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
MedGPA %>%
  ggplot(aes(x = GPA, y = Acceptance)) +
  geom_point() +
  geom_smooth(se=F, method="lm") +
  labs(x = "College GPA",
       y = "P(Accepted = 1)") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

--

.question[
What's wrong with this fit?
]

---

## Binary response

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
MedGPA %>%
  ggplot(aes(x = GPA, y = Acceptance)) +
  geom_point() +
  geom_smooth(se=F, method="lm") +
  labs(x = "College GPA",
       y = "P(Accepted = 1)") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

**Problem:** 
* probabilities (e.g., $P(Accepted = 1)$ ) are constrained to be between 0 and 1
* Lines are never constrained (unless the slope is 0)

---

## Binary response

**Better idea:** <ins>curved</ins> fit!

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
med_glm <- glm(Acceptance ~ GPA, data = MedGPA,
               family = binomial())

MedGPA %>%
  mutate(pred = predict(med_glm, type="response")) %>%
  ggplot(aes(x = GPA, y = Acceptance)) +
  geom_point() +
  geom_line(aes(y = pred),
            color = "blue", lwd=1.2) +
  labs(x = "College GPA",
       y = "P(Accepted = 1)") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

--

$P(\text{Accepted} = 1) = \beta_0 + \beta_1 \text{GPA} \hspace{2cm}$ NOT CURVED

**Transformation:** $f(P(\text{Accepted} = 1)) = \beta_0 + \beta_1 \text{GPA}$

--

.question[
We just need a good transformation!
]

---

## Logistic regression

```{r echo=F, message=F, fig.width=6, fig.height=4, fig.align='center'}
med_glm <- glm(Acceptance ~ GPA, data = MedGPA,
               family = binomial())

MedGPA %>%
  mutate(pred = predict(med_glm, type="response")) %>%
  ggplot(aes(x = GPA, y = Acceptance)) +
  geom_point() +
  geom_line(aes(y = pred),
            color = "blue", lwd=1.2) +
  labs(x = "College GPA",
       y = "P(Accepted = 1)") +
  theme_bw() +
  theme(text = element_text(size = 20))
```

$\pi = P(\text{Accepted} = 1)$

**Logistic regression model:** $\hspace{1cm} \log \left( \dfrac{\pi}{1 - \pi} \right) = \beta_0 + \beta_1 \text{GPA}$

---

## Odds

$\log \left( \dfrac{\pi}{1 - \pi} \right) = \beta_0 + \beta_1 \text{GPA}$

**Odds:** $\dfrac{\pi}{1 - \pi}$ is called the <ins>odds</ins>

--

If $\pi = P(\text{Accepted} = 1)$, then $\dfrac{\pi}{1 - \pi}$ is the odds of being accepted to medical school.

---

## Odds

**Odds:** $\dfrac{\pi}{1 - \pi}$

**Example:** Suppose you flip a fair coin ( $P(\text{Heads} = 1) = 0.5$ ). The odds the coin comes up heads are 

$\dfrac{0.5}{1 - 0.5} = \dfrac{0.5}{0.5} = \dfrac{1}{1} = 1$

*Note: This could also be written 1:1*

---

## Odds

**Odds:** $\dfrac{\pi}{1 - \pi}$

**Example:** Suppose you flip an unfair coin, with $P(\text{Heads} = 1) = 0.6$. The odds the coin comes up heads are:

.abox[
0.6
]

.bbox[
0.4
]

.cbox[
$\dfrac{0.6}{0.4} = \dfrac{1.5}{1} = 1.5$
]

.dbox[
$\dfrac{0.4}{0.6} = \dfrac{1}{1.5} = 0.667$
]

---

## Odds

**Odds:** $\dfrac{\pi}{1 - \pi}$

**Example:** Suppose you flip an unfair coin, with $P(\text{Heads} = 1) = 0.6$. The odds the coin comes up heads are:

.abox[
0.6
]

.bbox[
0.4
]

.cbox[
$\dfrac{0.6}{0.4} = \dfrac{1.5}{1} = 1.5$
]

.dbox[
$\dfrac{0.4}{0.6} = \dfrac{1}{1.5} = 0.667$
]

**Solution:** The odds are $\dfrac{0.6}{0.4} = \dfrac{1.5}{1} = 1.5$ (we could also write this 1.5:1)

---

## Example

.pull-left[
Study on whether transcranial magnetic stimulation (TMS) helps relieve migraine pain:

.center[
| | TMS | Placebo | Total |
| --- | --- | --- | --- |
| Pain free two hours later | 39 | 22 | 61 |
| Not pain free two hours later | 61 | 78 | 139 |
| Total | 100 | 100 | 200 |
]
]

.pull-right[
What fraction of TMS patients were pain free after 2 hours?

.abox[
0.39
]

.bbox[
0.22
]

.cbox[
0.61
]

.dbox[
0.64
]

]

--

**Answer:** 39/100 = 0.39 

---

## Example

.pull-left[
Study on whether transcranial magnetic stimulation (TMS) helps relieve migraine pain:

.center[
| | TMS | Placebo | Total |
| --- | --- | --- | --- |
| Pain free two hours later | 39 | 22 | 61 |
| Not pain free two hours later | 61 | 78 | 139 |
| Total | 100 | 100 | 200 |
]
]

.pull-right[
What are the odds of being pain free after 2 hours for the TMS group?

.abox[
0.39
]

.bbox[
0.64
]

.cbox[
0.22
]

.dbox[
1.56
]

]

--

**Answer:** (39/100)/(61/100) = 0.64

---

## Example

.pull-left[
Study on whether transcranial magnetic stimulation (TMS) helps relieve migraine pain:

.center[
| | TMS | Placebo | Total |
| --- | --- | --- | --- |
| Pain free two hours later | 39 | 22 | 61 |
| Not pain free two hours later | 61 | 78 | 139 |
| Total | 100 | 100 | 200 |
]
]

.pull-right[
What are the odds of being pain free after 2 hours for the placebo group?

.abox[
0.22
]

.bbox[
0.64
]

.cbox[
0.36
]

.dbox[
0.28
]

]

--

**Answer:** (22/100)/(78/100) = 0.28

---

## Odds ratio

.center[
| | TMS | Placebo | Total |
| --- | --- | --- | --- |
| Pain free two hours later | 39 | 22 | 61 |
| Not pain free two hours later | 61 | 78 | 139 |
| Total | 100 | 100 | 200 |
]

Odds of being pain free after 2 hours for TMS group: 0.64

Odds of being pain free after 2 hours for placebo group: 0.28

**Odds ratio:** $0.64/0.28 = 2.29$

.question[
The odds of being pain free after 2 hours were 2.29 times higher with TMS than with the placebo.
]

---

## Class activity

[https://sta112-f21.github.io/class_activities/ca_lecture_30.html](https://sta112-f21.github.io/class_activities/ca_lecture_30.html)

---

## GPA and med school acceptance

$\log \left( \dfrac{\widehat{\pi}}{1 - \widehat{\pi}} \right) = -19.21 + 5.45 \ \text{GPA}$

* Estimated odds of acceptance for a student with a 3.0 GPA: $\exp\{-19.21 + 5.45 \cdot 3\} = 0.0573$

--
* Estimated odds of acceptance for a student with a 4.0 GPA: $\exp\{-19.21 + 5.45 \cdot 4\} = 13.3298$

--
* Odds ratio: $13.3298/0.0573 = 233$
    * So the odds of acceptance are 233 times higher for a student with a GPA of 4.0 vs. 3.0

---

## GPA and med school acceptance

$\log \left( \dfrac{\widehat{\pi}}{1 - \widehat{\pi}} \right) = -19.21 + 5.45 \ \text{GPA}$

* Estimated odds of acceptance for a student with a 3.0 GPA: $\exp\{-19.21 + 5.45 \cdot 3\} = 0.0573$
* Estimated odds of acceptance for a student with a 4.0 GPA: $\exp\{-19.21 + 5.45 \cdot 4\} = 13.3298$
* Odds ratio: $13.3298/0.0573 = 233$
    * So the odds of acceptance are 233 times higher for a student with a GPA of 4.0 vs. 3.0
* The odds of acceptance are also 233 times higher for a student with a GPA of 3.8 vs. 2.8
    * An increase of 1 unit in GPA is associated with a change in odds of acceptance by a factor of 233
    * And $\exp\{\widehat{\beta}_1\} = \exp\{5.45\} = 233$

---

## Interpreting the fitted regression model

$\log \left( \dfrac{\widehat{\pi}}{1 - \widehat{\pi}} \right) = \widehat{\beta}_0 + \widehat{\beta}_1 \ x$

* $\exp\{\widehat{\beta}_0\} =$ estimated odds when $x = 0$
* $\exp\{\widehat{\beta}_1\} =$ estimated odds ratio for an increase of one unit in $x$